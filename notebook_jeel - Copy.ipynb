{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56955ab4",
   "metadata": {},
   "source": [
    "# Assessing Wikipedia Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd016c",
   "metadata": {},
   "source": [
    "## 1. You will need to collect data from a source of your choosing (dataset, wikipedia API, web-scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376d2cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fcdac3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91972697",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4602f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import xgboost as xgb\n",
    "from textblob import TextBlob\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8995c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'final_labels_SG2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_labels_SG2\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m data_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_articles.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the dataset\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final_labels_SG2'"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "data = pd.read_csv('final_labels_SG2', sep=';')\n",
    "\n",
    "\n",
    "data_1 = pd.read_csv('news_articles.csv')\n",
    "# Display the first few rows of the dataset\n",
    "display(data.head())\n",
    "display(data_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5b3d0",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5b3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'news_link',\n",
       " 'outlet',\n",
       " 'topic',\n",
       " 'type',\n",
       " 'group_id',\n",
       " 'num_sent',\n",
       " 'label_bias',\n",
       " 'label_opinion',\n",
       " 'article',\n",
       " 'biased_words']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['author',\n",
       " 'published',\n",
       " 'title',\n",
       " 'text',\n",
       " 'language',\n",
       " 'site_url',\n",
       " 'main_img_url',\n",
       " 'type',\n",
       " 'label',\n",
       " 'title_without_stopwords',\n",
       " 'text_without_stopwords',\n",
       " 'hasImage']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Display the column names of the dataset\n",
    "column_names = data.columns.tolist()\n",
    "display(column_names)\n",
    "\n",
    "column_names = data_1.columns.tolist()\n",
    "display(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa8dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame has 1700 rows and 11 columns\n",
      "The DataFrame has 2096 rows and 12 columns\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Display the shape of the dataset\n",
    "n_rows, n_cols = data.shape\n",
    "print(f\"The DataFrame has {n_rows} rows and {n_cols} columns\")\n",
    "\n",
    "# Display the shape of the dataset\n",
    "n_rows, n_cols = data_1.shape\n",
    "print(f\"The DataFrame has {n_rows} rows and {n_cols} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3998e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1700 entries, 0 to 1699\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   text           1700 non-null   object\n",
      " 1   news_link      1681 non-null   object\n",
      " 2   outlet         1700 non-null   object\n",
      " 3   topic          1700 non-null   object\n",
      " 4   type           1700 non-null   object\n",
      " 5   group_id       1700 non-null   int64 \n",
      " 6   num_sent       1700 non-null   int64 \n",
      " 7   label_bias     1700 non-null   object\n",
      " 8   label_opinion  1700 non-null   object\n",
      " 9   article        1595 non-null   object\n",
      " 10  biased_words   1700 non-null   object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 146.2+ KB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Display the informative summary of the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f9a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>num_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.124706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.542908</td>\n",
       "      <td>0.414256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          group_id     num_sent\n",
       "count  1700.000000  1700.000000\n",
       "mean     43.000000     1.124706\n",
       "std      24.542908     0.414256\n",
       "min       1.000000     1.000000\n",
       "25%      22.000000     1.000000\n",
       "50%      43.000000     1.000000\n",
       "75%      64.000000     1.000000\n",
       "max      85.000000     5.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Display the descriptive statistics of the dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc2dbd",
   "metadata": {},
   "source": [
    "## 2. You will conduct EDA that you see fit to appropriately investigate text of wikipedia articles you look to predict on for biased terms, sentiment, or other linguistic significance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910da4e2",
   "metadata": {},
   "source": [
    "## Explorating Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9456da3",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ad12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of duplicated data: 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Display the number of duplicates in the dataset\n",
    "duplicates = data[data.duplicated()]\n",
    "display(f\"Number of duplicated data: {duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46d36b",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c2a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text               0\n",
       "news_link         19\n",
       "outlet             0\n",
       "topic              0\n",
       "type               0\n",
       "group_id           0\n",
       "num_sent           0\n",
       "label_bias         0\n",
       "label_opinion      0\n",
       "article          105\n",
       "biased_words       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text             0.000000\n",
       "news_link        0.011176\n",
       "outlet           0.000000\n",
       "topic            0.000000\n",
       "type             0.000000\n",
       "group_id         0.000000\n",
       "num_sent         0.000000\n",
       "label_bias       0.000000\n",
       "label_opinion    0.000000\n",
       "article          0.061765\n",
       "biased_words     0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Display the number of missing values in the dataset\n",
    "display(data.isna().sum())\n",
    "\n",
    "# Check for missing values in the DataFrame as a percentage\n",
    "display(data.isna().sum()/len(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cde572",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in the 'news_link' and 'article' columns\n",
    "data.dropna(subset=['news_link'], inplace=True)\n",
    "data.dropna(subset=['article'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12601f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text             0.0\n",
       "news_link        0.0\n",
       "outlet           0.0\n",
       "topic            0.0\n",
       "type             0.0\n",
       "group_id         0.0\n",
       "num_sent         0.0\n",
       "label_bias       0.0\n",
       "label_opinion    0.0\n",
       "article          0.0\n",
       "biased_words     0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Check for missing values in the DataFrame as a percentage\n",
    "display(data.isna().sum()/len(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81246efe",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Cleaning the text data in the 'text' column\n",
    "# Define a function to clean the text data \n",
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\",\"\", text)\n",
    "    text = text.split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55422bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data['label_bias'] = data['label_bias'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abffc4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>group_id</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>label_bias</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>article</th>\n",
       "      <th>biased_words</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>https://thefederalist.com/2019/11/08/nationali...</td>\n",
       "      <td>federalist</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>right</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>First Things editor R.R. Reno's book, 'Return ...</td>\n",
       "      <td>['intolerant', 'authoritarianism', 'haunting']</td>\n",
       "      <td>a specter is haunting the west our elites see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>https://www.foxnews.com/politics/trump-pokes-f...</td>\n",
       "      <td>fox-news</td>\n",
       "      <td>environment</td>\n",
       "      <td>right</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>no agreement</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>President Trump poked fun at Sen. Amy Klobucha...</td>\n",
       "      <td>['poked', 'fun']</td>\n",
       "      <td>president trump poked fun at sen amy klobuchar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>https://www.reuters.com/article/us-usa-electio...</td>\n",
       "      <td>reuters</td>\n",
       "      <td>elections-2020</td>\n",
       "      <td>center</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>WILMINGTON, Del. (Reuters) - Democratic presid...</td>\n",
       "      <td>['contrast']</td>\n",
       "      <td>bidens appearance was a contrast with the appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>https://www.foxnews.com/politics/democrats-rej...</td>\n",
       "      <td>fox-news</td>\n",
       "      <td>immigration</td>\n",
       "      <td>right</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>non-biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>Democrats this week approved legislation to re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>democrats this week approved legislation to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>https://www.alternet.org/2020/05/why-the-calls...</td>\n",
       "      <td>alternet</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>left</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>no agreement</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>When the coronavirus pandemic was first declar...</td>\n",
       "      <td>['racialized', 'epicenter']</td>\n",
       "      <td>in new york city the national epicenter of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              news_link      outlet  \\\n",
       "772   https://thefederalist.com/2019/11/08/nationali...  federalist   \n",
       "1092  https://www.foxnews.com/politics/trump-pokes-f...    fox-news   \n",
       "41    https://www.reuters.com/article/us-usa-electio...     reuters   \n",
       "1280  https://www.foxnews.com/politics/democrats-rej...    fox-news   \n",
       "1154  https://www.alternet.org/2020/05/why-the-calls...    alternet   \n",
       "\n",
       "                  topic    type  group_id  num_sent    label_bias  \\\n",
       "772   white-nationalism   right        67         1        biased   \n",
       "1092        environment   right        38         1  no agreement   \n",
       "41       elections-2020  center         4         1        biased   \n",
       "1280        immigration   right        14         1    non-biased   \n",
       "1154        coronavirus    left        72         1  no agreement   \n",
       "\n",
       "                              label_opinion  \\\n",
       "772              Expresses writer’s opinion   \n",
       "1092  Somewhat factual but also opinionated   \n",
       "41               Expresses writer’s opinion   \n",
       "1280                       Entirely factual   \n",
       "1154                       Entirely factual   \n",
       "\n",
       "                                                article  \\\n",
       "772   First Things editor R.R. Reno's book, 'Return ...   \n",
       "1092  President Trump poked fun at Sen. Amy Klobucha...   \n",
       "41    WILMINGTON, Del. (Reuters) - Democratic presid...   \n",
       "1280  Democrats this week approved legislation to re...   \n",
       "1154  When the coronavirus pandemic was first declar...   \n",
       "\n",
       "                                        biased_words  \\\n",
       "772   ['intolerant', 'authoritarianism', 'haunting']   \n",
       "1092                                ['poked', 'fun']   \n",
       "41                                      ['contrast']   \n",
       "1280                                              []   \n",
       "1154                     ['racialized', 'epicenter']   \n",
       "\n",
       "                                             clean_text  \n",
       "772   a specter is haunting the west our elites see ...  \n",
       "1092  president trump poked fun at sen amy klobuchar...  \n",
       "41    bidens appearance was a contrast with the appr...  \n",
       "1280  democrats this week approved legislation to re...  \n",
       "1154  in new york city the national epicenter of the...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Apply the clear_text function to the 'comment_text' column\n",
    "data['clean_text'] = data['text'].astype(str).apply(clear_text) \n",
    "data= data.drop(columns=['text'])\n",
    "\n",
    "# Display the first 5 rows of the comments DataFrame after cleaning\n",
    "display(data.sample(5)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b0b8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data['clean_text'].isna().sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1576 entries, 0 to 1699\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   news_link      1576 non-null   object\n",
      " 1   outlet         1576 non-null   object\n",
      " 2   topic          1576 non-null   object\n",
      " 3   type           1576 non-null   object\n",
      " 4   group_id       1576 non-null   int64 \n",
      " 5   num_sent       1576 non-null   int64 \n",
      " 6   label_bias     1576 non-null   object\n",
      " 7   label_opinion  1576 non-null   object\n",
      " 8   article        1576 non-null   object\n",
      " 9   biased_words   1576 non-null   object\n",
      " 10  clean_text     1576 non-null   object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 147.8+ KB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8b8ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## Set of English stop words\n",
    "stop_words =  set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458c7dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def lemmatize(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57095114",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Apply the clear_text function to the 'comment_text' column\n",
    "data['lemmatize_text'] = data['clean_text'].apply(lemmatize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e568e71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemmatize_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube is making clear there will be no birth...</td>\n",
       "      <td>youtube making clear birtherism platform year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so while there may be a humanitarian crisis dr...</td>\n",
       "      <td>may humanitarian crisis driving vulnerable peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking around the united states there is neve...</td>\n",
       "      <td>looking around united state never enough welfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the republican president assumed he was helpin...</td>\n",
       "      <td>republican president assumed helping industry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the explosion of the hispanic population has l...</td>\n",
       "      <td>explosion hispanic population longterm job pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the antivaccine movement made headlines last s...</td>\n",
       "      <td>antivaccine movement made headline last spring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>voting in quasimilitarized settings was not co...</td>\n",
       "      <td>voting quasimilitarized setting confined natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>but one glaring absentee was trump who not onl...</td>\n",
       "      <td>one glaring absentee trump declined invitation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>track and field athletes dont typically earn t...</td>\n",
       "      <td>track field athlete dont typically earn lucrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in other words the agency responsible for prot...</td>\n",
       "      <td>word agency responsible protecting consumer wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a catholic priest in rhode island who barred s...</td>\n",
       "      <td>catholic priest rhode island barred state lawm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gwyneth paltrows antivaxxer ally comes under f...</td>\n",
       "      <td>gwyneth paltrows antivaxxer ally come fire dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gadsbys work is a testament to how eagerly the...</td>\n",
       "      <td>gadsbys work testament eagerly arbiter culture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thats led some vaccine foes to join the protes...</td>\n",
       "      <td>thats led vaccine foe join protester trump enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>thats why white nationalists who are enthusias...</td>\n",
       "      <td>thats white nationalist enthusiast abortion bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>biden was particularly critical of trumps visi...</td>\n",
       "      <td>biden particularly critical trump visit monday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>young women taking part in high school and col...</td>\n",
       "      <td>young woman taking part high school college at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>under current immigration policies its possibl...</td>\n",
       "      <td>current immigration policy possible immigratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lessorganized migrants tighter immigration con...</td>\n",
       "      <td>lessorganized migrant tighter immigration cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trump enjoys and encourages state brutality ag...</td>\n",
       "      <td>trump enjoys encourages state brutality people...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_text  \\\n",
       "0   youtube is making clear there will be no birth...   \n",
       "1   so while there may be a humanitarian crisis dr...   \n",
       "2   looking around the united states there is neve...   \n",
       "3   the republican president assumed he was helpin...   \n",
       "4   the explosion of the hispanic population has l...   \n",
       "5   the antivaccine movement made headlines last s...   \n",
       "6   voting in quasimilitarized settings was not co...   \n",
       "7   but one glaring absentee was trump who not onl...   \n",
       "9   track and field athletes dont typically earn t...   \n",
       "10  in other words the agency responsible for prot...   \n",
       "11  a catholic priest in rhode island who barred s...   \n",
       "12  gwyneth paltrows antivaxxer ally comes under f...   \n",
       "14  gadsbys work is a testament to how eagerly the...   \n",
       "15  thats led some vaccine foes to join the protes...   \n",
       "16  thats why white nationalists who are enthusias...   \n",
       "17  biden was particularly critical of trumps visi...   \n",
       "18  young women taking part in high school and col...   \n",
       "19  under current immigration policies its possibl...   \n",
       "20  lessorganized migrants tighter immigration con...   \n",
       "21  trump enjoys and encourages state brutality ag...   \n",
       "\n",
       "                                       lemmatize_text  \n",
       "0   youtube making clear birtherism platform year ...  \n",
       "1   may humanitarian crisis driving vulnerable peo...  \n",
       "2   looking around united state never enough welfa...  \n",
       "3   republican president assumed helping industry ...  \n",
       "4   explosion hispanic population longterm job pro...  \n",
       "5   antivaccine movement made headline last spring...  \n",
       "6   voting quasimilitarized setting confined natio...  \n",
       "7   one glaring absentee trump declined invitation...  \n",
       "9   track field athlete dont typically earn lucrat...  \n",
       "10  word agency responsible protecting consumer wa...  \n",
       "11  catholic priest rhode island barred state lawm...  \n",
       "12  gwyneth paltrows antivaxxer ally come fire dis...  \n",
       "14  gadsbys work testament eagerly arbiter culture...  \n",
       "15  thats led vaccine foe join protester trump enc...  \n",
       "16  thats white nationalist enthusiast abortion bl...  \n",
       "17  biden particularly critical trump visit monday...  \n",
       "18  young woman taking part high school college at...  \n",
       "19  current immigration policy possible immigratio...  \n",
       "20  lessorganized migrant tighter immigration cont...  \n",
       "21  trump enjoys encourages state brutality people...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows of the comments DataFrame after cleaning\n",
    "display(data[['clean_text', 'lemmatize_text']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c4e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1576, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a9600",
   "metadata": {},
   "source": [
    "## 3. You will conduct supervised learning to be able to predict if a given text is biased. You might want to be able to do this on the sentence by sentence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908cf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['news_link', 'outlet', 'topic', 'type', 'group_id', 'num_sent',\n",
       "       'label_bias', 'label_opinion', 'article', 'biased_words', 'clean_text',\n",
       "       'lemmatize_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e87c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_bias\n",
       "biased          975\n",
       "non-biased      465\n",
       "no agreement    136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data['label_bias'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32996523",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# def get_sentiment(text):\n",
    "#    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "#data['biased_score'] = data['clean_text'].apply(get_sentiment)\n",
    "#data['biased_label'] = data['biased_score'].apply(lambda x: 'biased' if x > 0 else 'unbiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410a4dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6708860759493671\n",
      "[[193   0  11]\n",
      " [ 31   0   2]\n",
      " [ 60   0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      biased       0.68      0.95      0.79       204\n",
      "no agreement       0.00      0.00      0.00        33\n",
      "  non-biased       0.59      0.24      0.34        79\n",
      "\n",
      "    accuracy                           0.67       316\n",
      "   macro avg       0.42      0.40      0.38       316\n",
      "weighted avg       0.59      0.67      0.60       316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['clean_text'], data['label_bias'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0321534",
   "metadata": {},
   "source": [
    "## 4. You need to have a prediction function that can take in a new wikipedia article and predict how biased it is. You can do this by predicting if each sentence in an article is biased, then perhaps scaling the results by the length of the article to get somewhat of a“bias score”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
