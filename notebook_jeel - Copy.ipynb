{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56955ab4",
   "metadata": {},
   "source": [
    "# Assessing Wikipedia Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd016c",
   "metadata": {},
   "source": [
    "## 1. You will need to collect data from a source of your choosing (dataset, wikipedia API, web-scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376d2cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fcdac3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91972697",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4602f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import xgboost as xgb\n",
    "from textblob import TextBlob\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8995c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>group_id</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>label_bias</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>article</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YouTube is making clear there will be no “birt...</td>\n",
       "      <td>https://eu.usatoday.com/story/tech/2020/02/03/...</td>\n",
       "      <td>usa-today</td>\n",
       "      <td>elections-2020</td>\n",
       "      <td>center</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>YouTube says no ‘deepfakes’ or ‘birther’ video...</td>\n",
       "      <td>['belated', 'birtherism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So while there may be a humanitarian crisis dr...</td>\n",
       "      <td>https://www.alternet.org/2019/01/here-are-5-of...</td>\n",
       "      <td>alternet</td>\n",
       "      <td>immigration</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>Speaking to the country for the first time fro...</td>\n",
       "      <td>['crisis']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Looking around the United States, there is nev...</td>\n",
       "      <td>https://thefederalist.com/2020/03/11/woman-who...</td>\n",
       "      <td>federalist</td>\n",
       "      <td>abortion</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>The left has a thing for taking babies hostage...</td>\n",
       "      <td>['killing', 'never', 'developing', 'humans', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Republican president assumed he was helpin...</td>\n",
       "      <td>http://www.msnbc.com/rachel-maddow-show/auto-i...</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>environment</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>In Barack Obama’s first term, the administrati...</td>\n",
       "      <td>['rejects', 'happy', 'assumed']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The explosion of the Hispanic population has l...</td>\n",
       "      <td>https://www.breitbart.com/politics/2015/02/26/...</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>student-debt</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>No agreement</td>\n",
       "      <td>Republicans should stop fighting amnesty, Pres...</td>\n",
       "      <td>['explosion']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  YouTube is making clear there will be no “birt...   \n",
       "1  So while there may be a humanitarian crisis dr...   \n",
       "2  Looking around the United States, there is nev...   \n",
       "3  The Republican president assumed he was helpin...   \n",
       "4  The explosion of the Hispanic population has l...   \n",
       "\n",
       "                                           news_link      outlet  \\\n",
       "0  https://eu.usatoday.com/story/tech/2020/02/03/...   usa-today   \n",
       "1  https://www.alternet.org/2019/01/here-are-5-of...    alternet   \n",
       "2  https://thefederalist.com/2020/03/11/woman-who...  federalist   \n",
       "3  http://www.msnbc.com/rachel-maddow-show/auto-i...       msnbc   \n",
       "4  https://www.breitbart.com/politics/2015/02/26/...   breitbart   \n",
       "\n",
       "            topic    type  group_id  num_sent label_bias  \\\n",
       "0  elections-2020  center         1         1     Biased   \n",
       "1     immigration    left         1         1     Biased   \n",
       "2        abortion   right         1         1     Biased   \n",
       "3     environment    left         1         1     Biased   \n",
       "4    student-debt   right         1         1     Biased   \n",
       "\n",
       "                           label_opinion  \\\n",
       "0  Somewhat factual but also opinionated   \n",
       "1             Expresses writer’s opinion   \n",
       "2  Somewhat factual but also opinionated   \n",
       "3             Expresses writer’s opinion   \n",
       "4                           No agreement   \n",
       "\n",
       "                                             article  \\\n",
       "0  YouTube says no ‘deepfakes’ or ‘birther’ video...   \n",
       "1  Speaking to the country for the first time fro...   \n",
       "2  The left has a thing for taking babies hostage...   \n",
       "3  In Barack Obama’s first term, the administrati...   \n",
       "4  Republicans should stop fighting amnesty, Pres...   \n",
       "\n",
       "                                        biased_words  \n",
       "0                          ['belated', 'birtherism']  \n",
       "1                                         ['crisis']  \n",
       "2  ['killing', 'never', 'developing', 'humans', '...  \n",
       "3                    ['rejects', 'happy', 'assumed']  \n",
       "4                                      ['explosion']  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>site_url</th>\n",
       "      <th>main_img_url</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "      <th>title_without_stopwords</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "      <th>hasImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
       "      <td>muslims busted they stole millions in govt ben...</td>\n",
       "      <td>print they should pay all the back all the mon...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>muslims busted stole millions govt benefits</td>\n",
       "      <td>print pay back money plus interest entire fami...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reasoning with facts</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>re why did attorney general loretta lynch plea...</td>\n",
       "      <td>why did attorney general loretta lynch plead t...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>attorney general loretta lynch plead fifth</td>\n",
       "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>breaking weiner cooperating with fbi on hillar...</td>\n",
       "      <td>red state  \\nfox news sunday reported this mor...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
       "      <td>red state fox news sunday reported morning ant...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
       "      <td>pin drop speech by father of daughter kidnappe...</td>\n",
       "      <td>email kayla mueller was a prisoner and torture...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>pin drop speech father daughter kidnapped kill...</td>\n",
       "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
       "      <td>fantastic trumps  point plan to reform healthc...</td>\n",
       "      <td>email healthcare reform to make america great ...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>fantastic trumps point plan reform healthcare ...</td>\n",
       "      <td>email healthcare reform make america great sin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                      published  \\\n",
       "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
       "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
       "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
       "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
       "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  muslims busted they stole millions in govt ben...   \n",
       "1  re why did attorney general loretta lynch plea...   \n",
       "2  breaking weiner cooperating with fbi on hillar...   \n",
       "3  pin drop speech by father of daughter kidnappe...   \n",
       "4  fantastic trumps  point plan to reform healthc...   \n",
       "\n",
       "                                                text language  \\\n",
       "0  print they should pay all the back all the mon...  english   \n",
       "1  why did attorney general loretta lynch plead t...  english   \n",
       "2  red state  \\nfox news sunday reported this mor...  english   \n",
       "3  email kayla mueller was a prisoner and torture...  english   \n",
       "4  email healthcare reform to make america great ...  english   \n",
       "\n",
       "              site_url                                       main_img_url  \\\n",
       "0  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
       "1  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
       "2  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
       "3  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
       "4  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
       "\n",
       "   type label                            title_without_stopwords  \\\n",
       "0  bias  Real        muslims busted stole millions govt benefits   \n",
       "1  bias  Real         attorney general loretta lynch plead fifth   \n",
       "2  bias  Real  breaking weiner cooperating fbi hillary email ...   \n",
       "3  bias  Real  pin drop speech father daughter kidnapped kill...   \n",
       "4  bias  Real  fantastic trumps point plan reform healthcare ...   \n",
       "\n",
       "                              text_without_stopwords  hasImage  \n",
       "0  print pay back money plus interest entire fami...       1.0  \n",
       "1  attorney general loretta lynch plead fifth bar...       1.0  \n",
       "2  red state fox news sunday reported morning ant...       1.0  \n",
       "3  email kayla mueller prisoner tortured isis cha...       1.0  \n",
       "4  email healthcare reform make america great sin...       1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "data = pd.read_csv('final_labels.csv', sep=';')\n",
    "data_1 = pd.read_csv('news_articles.csv')\n",
    "# Display the first few rows of the dataset\n",
    "display(data.head())\n",
    "display(data_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5b3d0",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d5b3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'news_link',\n",
       " 'outlet',\n",
       " 'topic',\n",
       " 'type',\n",
       " 'group_id',\n",
       " 'num_sent',\n",
       " 'label_bias',\n",
       " 'label_opinion',\n",
       " 'article',\n",
       " 'biased_words']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['author',\n",
       " 'published',\n",
       " 'title',\n",
       " 'text',\n",
       " 'language',\n",
       " 'site_url',\n",
       " 'main_img_url',\n",
       " 'type',\n",
       " 'label',\n",
       " 'title_without_stopwords',\n",
       " 'text_without_stopwords',\n",
       " 'hasImage']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the column names of the dataset\n",
    "column_names = data.columns.tolist()\n",
    "display(column_names)\n",
    "\n",
    "column_names = data_1.columns.tolist()\n",
    "display(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebfa8dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame has 1700 rows and 11 columns\n",
      "The DataFrame has 2096 rows and 12 columns\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the dataset\n",
    "n_rows, n_cols = data.shape\n",
    "print(f\"The DataFrame has {n_rows} rows and {n_cols} columns\")\n",
    "\n",
    "# Display the shape of the dataset\n",
    "n_rows, n_cols = data_1.shape\n",
    "print(f\"The DataFrame has {n_rows} rows and {n_cols} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3998e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1700 entries, 0 to 1699\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   text           1700 non-null   object\n",
      " 1   news_link      1681 non-null   object\n",
      " 2   outlet         1700 non-null   object\n",
      " 3   topic          1700 non-null   object\n",
      " 4   type           1700 non-null   object\n",
      " 5   group_id       1700 non-null   int64 \n",
      " 6   num_sent       1700 non-null   int64 \n",
      " 7   label_bias     1700 non-null   object\n",
      " 8   label_opinion  1700 non-null   object\n",
      " 9   article        1595 non-null   object\n",
      " 10  biased_words   1700 non-null   object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 146.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display the informative summary of the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486f9a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>num_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.124706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.542908</td>\n",
       "      <td>0.414256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          group_id     num_sent\n",
       "count  1700.000000  1700.000000\n",
       "mean     43.000000     1.124706\n",
       "std      24.542908     0.414256\n",
       "min       1.000000     1.000000\n",
       "25%      22.000000     1.000000\n",
       "50%      43.000000     1.000000\n",
       "75%      64.000000     1.000000\n",
       "max      85.000000     5.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the descriptive statistics of the dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc2dbd",
   "metadata": {},
   "source": [
    "## 2. You will conduct EDA that you see fit to appropriately investigate text of wikipedia articles you look to predict on for biased terms, sentiment, or other linguistic significance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910da4e2",
   "metadata": {},
   "source": [
    "## Explorating Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9456da3",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "998ad12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of duplicated data: 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the number of duplicates in the dataset\n",
    "duplicates = data[data.duplicated()]\n",
    "display(f\"Number of duplicated data: {duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46d36b",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f75c2a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text               0\n",
       "news_link         19\n",
       "outlet             0\n",
       "topic              0\n",
       "type               0\n",
       "group_id           0\n",
       "num_sent           0\n",
       "label_bias         0\n",
       "label_opinion      0\n",
       "article          105\n",
       "biased_words       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text             0.000000\n",
       "news_link        0.011176\n",
       "outlet           0.000000\n",
       "topic            0.000000\n",
       "type             0.000000\n",
       "group_id         0.000000\n",
       "num_sent         0.000000\n",
       "label_bias       0.000000\n",
       "label_opinion    0.000000\n",
       "article          0.061765\n",
       "biased_words     0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the number of missing values in the dataset\n",
    "display(data.isna().sum())\n",
    "\n",
    "# Check for missing values in the DataFrame as a percentage\n",
    "display(data.isna().sum()/len(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40cde572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the 'news_link' and 'article' columns\n",
    "data.dropna(subset=['news_link'], inplace=True)\n",
    "data.dropna(subset=['article'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b12601f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text             0.0\n",
       "news_link        0.0\n",
       "outlet           0.0\n",
       "topic            0.0\n",
       "type             0.0\n",
       "group_id         0.0\n",
       "num_sent         0.0\n",
       "label_bias       0.0\n",
       "label_opinion    0.0\n",
       "article          0.0\n",
       "biased_words     0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for missing values in the DataFrame as a percentage\n",
    "display(data.isna().sum()/len(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81246efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text data in the 'text' column\n",
    "# Define a function to clean the text data \n",
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\",\"\", text)\n",
    "    text = text.split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f55422bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label_bias'] = data['label_bias'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abffc4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>group_id</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>label_bias</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>article</th>\n",
       "      <th>biased_words</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>https://thefederalist.com/2019/11/08/nationali...</td>\n",
       "      <td>federalist</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>right</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>First Things editor R.R. Reno's book, 'Return ...</td>\n",
       "      <td>['intolerant', 'authoritarianism', 'haunting']</td>\n",
       "      <td>a specter is haunting the west our elites see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>https://www.foxnews.com/politics/trump-pokes-f...</td>\n",
       "      <td>fox-news</td>\n",
       "      <td>environment</td>\n",
       "      <td>right</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>no agreement</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>President Trump poked fun at Sen. Amy Klobucha...</td>\n",
       "      <td>['poked', 'fun']</td>\n",
       "      <td>president trump poked fun at sen amy klobuchar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>https://www.reuters.com/article/us-usa-electio...</td>\n",
       "      <td>reuters</td>\n",
       "      <td>elections-2020</td>\n",
       "      <td>center</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>WILMINGTON, Del. (Reuters) - Democratic presid...</td>\n",
       "      <td>['contrast']</td>\n",
       "      <td>bidens appearance was a contrast with the appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>https://www.foxnews.com/politics/democrats-rej...</td>\n",
       "      <td>fox-news</td>\n",
       "      <td>immigration</td>\n",
       "      <td>right</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>non-biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>Democrats this week approved legislation to re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>democrats this week approved legislation to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>https://www.alternet.org/2020/05/why-the-calls...</td>\n",
       "      <td>alternet</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>left</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>no agreement</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>When the coronavirus pandemic was first declar...</td>\n",
       "      <td>['racialized', 'epicenter']</td>\n",
       "      <td>in new york city the national epicenter of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              news_link      outlet  \\\n",
       "772   https://thefederalist.com/2019/11/08/nationali...  federalist   \n",
       "1092  https://www.foxnews.com/politics/trump-pokes-f...    fox-news   \n",
       "41    https://www.reuters.com/article/us-usa-electio...     reuters   \n",
       "1280  https://www.foxnews.com/politics/democrats-rej...    fox-news   \n",
       "1154  https://www.alternet.org/2020/05/why-the-calls...    alternet   \n",
       "\n",
       "                  topic    type  group_id  num_sent    label_bias  \\\n",
       "772   white-nationalism   right        67         1        biased   \n",
       "1092        environment   right        38         1  no agreement   \n",
       "41       elections-2020  center         4         1        biased   \n",
       "1280        immigration   right        14         1    non-biased   \n",
       "1154        coronavirus    left        72         1  no agreement   \n",
       "\n",
       "                              label_opinion  \\\n",
       "772              Expresses writer’s opinion   \n",
       "1092  Somewhat factual but also opinionated   \n",
       "41               Expresses writer’s opinion   \n",
       "1280                       Entirely factual   \n",
       "1154                       Entirely factual   \n",
       "\n",
       "                                                article  \\\n",
       "772   First Things editor R.R. Reno's book, 'Return ...   \n",
       "1092  President Trump poked fun at Sen. Amy Klobucha...   \n",
       "41    WILMINGTON, Del. (Reuters) - Democratic presid...   \n",
       "1280  Democrats this week approved legislation to re...   \n",
       "1154  When the coronavirus pandemic was first declar...   \n",
       "\n",
       "                                        biased_words  \\\n",
       "772   ['intolerant', 'authoritarianism', 'haunting']   \n",
       "1092                                ['poked', 'fun']   \n",
       "41                                      ['contrast']   \n",
       "1280                                              []   \n",
       "1154                     ['racialized', 'epicenter']   \n",
       "\n",
       "                                             clean_text  \n",
       "772   a specter is haunting the west our elites see ...  \n",
       "1092  president trump poked fun at sen amy klobuchar...  \n",
       "41    bidens appearance was a contrast with the appr...  \n",
       "1280  democrats this week approved legislation to re...  \n",
       "1154  in new york city the national epicenter of the...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the clear_text function to the 'comment_text' column\n",
    "data['clean_text'] = data['text'].astype(str).apply(clear_text) \n",
    "data= data.drop(columns=['text'])\n",
    "\n",
    "# Display the first 5 rows of the comments DataFrame after cleaning\n",
    "display(data.sample(5)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41b0b8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data['clean_text'].isna().sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9744ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1576 entries, 0 to 1699\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   news_link      1576 non-null   object\n",
      " 1   outlet         1576 non-null   object\n",
      " 2   topic          1576 non-null   object\n",
      " 3   type           1576 non-null   object\n",
      " 4   group_id       1576 non-null   int64 \n",
      " 5   num_sent       1576 non-null   int64 \n",
      " 6   label_bias     1576 non-null   object\n",
      " 7   label_opinion  1576 non-null   object\n",
      " 8   article        1576 non-null   object\n",
      " 9   biased_words   1576 non-null   object\n",
      " 10  clean_text     1576 non-null   object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 147.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16c8b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set of English stop words\n",
    "stop_words =  set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f458c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def lemmatize(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57095114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clear_text function to the 'comment_text' column\n",
    "data['lemmatize_text'] = data['clean_text'].apply(lemmatize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e568e71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemmatize_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube is making clear there will be no birth...</td>\n",
       "      <td>youtube making clear birtherism platform year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so while there may be a humanitarian crisis dr...</td>\n",
       "      <td>may humanitarian crisis driving vulnerable peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking around the united states there is neve...</td>\n",
       "      <td>looking around united state never enough welfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the republican president assumed he was helpin...</td>\n",
       "      <td>republican president assumed helping industry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the explosion of the hispanic population has l...</td>\n",
       "      <td>explosion hispanic population longterm job pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the antivaccine movement made headlines last s...</td>\n",
       "      <td>antivaccine movement made headline last spring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>voting in quasimilitarized settings was not co...</td>\n",
       "      <td>voting quasimilitarized setting confined natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>but one glaring absentee was trump who not onl...</td>\n",
       "      <td>one glaring absentee trump declined invitation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>track and field athletes dont typically earn t...</td>\n",
       "      <td>track field athlete dont typically earn lucrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in other words the agency responsible for prot...</td>\n",
       "      <td>word agency responsible protecting consumer wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a catholic priest in rhode island who barred s...</td>\n",
       "      <td>catholic priest rhode island barred state lawm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gwyneth paltrows antivaxxer ally comes under f...</td>\n",
       "      <td>gwyneth paltrows antivaxxer ally come fire dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gadsbys work is a testament to how eagerly the...</td>\n",
       "      <td>gadsbys work testament eagerly arbiter culture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thats led some vaccine foes to join the protes...</td>\n",
       "      <td>thats led vaccine foe join protester trump enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>thats why white nationalists who are enthusias...</td>\n",
       "      <td>thats white nationalist enthusiast abortion bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>biden was particularly critical of trumps visi...</td>\n",
       "      <td>biden particularly critical trump visit monday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>young women taking part in high school and col...</td>\n",
       "      <td>young woman taking part high school college at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>under current immigration policies its possibl...</td>\n",
       "      <td>current immigration policy possible immigratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lessorganized migrants tighter immigration con...</td>\n",
       "      <td>lessorganized migrant tighter immigration cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trump enjoys and encourages state brutality ag...</td>\n",
       "      <td>trump enjoys encourages state brutality people...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_text  \\\n",
       "0   youtube is making clear there will be no birth...   \n",
       "1   so while there may be a humanitarian crisis dr...   \n",
       "2   looking around the united states there is neve...   \n",
       "3   the republican president assumed he was helpin...   \n",
       "4   the explosion of the hispanic population has l...   \n",
       "5   the antivaccine movement made headlines last s...   \n",
       "6   voting in quasimilitarized settings was not co...   \n",
       "7   but one glaring absentee was trump who not onl...   \n",
       "9   track and field athletes dont typically earn t...   \n",
       "10  in other words the agency responsible for prot...   \n",
       "11  a catholic priest in rhode island who barred s...   \n",
       "12  gwyneth paltrows antivaxxer ally comes under f...   \n",
       "14  gadsbys work is a testament to how eagerly the...   \n",
       "15  thats led some vaccine foes to join the protes...   \n",
       "16  thats why white nationalists who are enthusias...   \n",
       "17  biden was particularly critical of trumps visi...   \n",
       "18  young women taking part in high school and col...   \n",
       "19  under current immigration policies its possibl...   \n",
       "20  lessorganized migrants tighter immigration con...   \n",
       "21  trump enjoys and encourages state brutality ag...   \n",
       "\n",
       "                                       lemmatize_text  \n",
       "0   youtube making clear birtherism platform year ...  \n",
       "1   may humanitarian crisis driving vulnerable peo...  \n",
       "2   looking around united state never enough welfa...  \n",
       "3   republican president assumed helping industry ...  \n",
       "4   explosion hispanic population longterm job pro...  \n",
       "5   antivaccine movement made headline last spring...  \n",
       "6   voting quasimilitarized setting confined natio...  \n",
       "7   one glaring absentee trump declined invitation...  \n",
       "9   track field athlete dont typically earn lucrat...  \n",
       "10  word agency responsible protecting consumer wa...  \n",
       "11  catholic priest rhode island barred state lawm...  \n",
       "12  gwyneth paltrows antivaxxer ally come fire dis...  \n",
       "14  gadsbys work testament eagerly arbiter culture...  \n",
       "15  thats led vaccine foe join protester trump enc...  \n",
       "16  thats white nationalist enthusiast abortion bl...  \n",
       "17  biden particularly critical trump visit monday...  \n",
       "18  young woman taking part high school college at...  \n",
       "19  current immigration policy possible immigratio...  \n",
       "20  lessorganized migrant tighter immigration cont...  \n",
       "21  trump enjoys encourages state brutality people...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 5 rows of the comments DataFrame after cleaning\n",
    "display(data[['clean_text', 'lemmatize_text']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a1c4e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1576, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a9600",
   "metadata": {},
   "source": [
    "## 3. You will conduct supervised learning to be able to predict if a given text is biased. You might want to be able to do this on the sentence by sentence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7908cf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['news_link', 'outlet', 'topic', 'type', 'group_id', 'num_sent',\n",
       "       'label_bias', 'label_opinion', 'article', 'biased_words', 'clean_text',\n",
       "       'lemmatize_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8e87c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_bias\n",
       "biased          975\n",
       "non-biased      465\n",
       "no agreement    136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label_bias'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32996523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sentiment(text):\n",
    "#    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "#data['biased_score'] = data['clean_text'].apply(get_sentiment)\n",
    "#data['biased_label'] = data['biased_score'].apply(lambda x: 'biased' if x > 0 else 'unbiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "410a4dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6708860759493671\n",
      "[[193   0  11]\n",
      " [ 31   0   2]\n",
      " [ 60   0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      biased       0.68      0.95      0.79       204\n",
      "no agreement       0.00      0.00      0.00        33\n",
      "  non-biased       0.59      0.24      0.34        79\n",
      "\n",
      "    accuracy                           0.67       316\n",
      "   macro avg       0.42      0.40      0.38       316\n",
      "weighted avg       0.59      0.67      0.60       316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['clean_text'], data['label_bias'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0321534",
   "metadata": {},
   "source": [
    "## 4. You need to have a prediction function that can take in a new wikipedia article and predict how biased it is. You can do this by predicting if each sentence in an article is biased, then perhaps scaling the results by the length of the article to get somewhat of a“bias score”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
