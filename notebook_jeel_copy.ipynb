{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56955ab4",
   "metadata": {},
   "source": [
    "# Assessing Wikipedia Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd016c",
   "metadata": {},
   "source": [
    "## 1. You will need to collect data from a source of your choosing (dataset, wikipedia API, web-scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376d2cc",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcdac3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91972697",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4602f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8995c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>group_id</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>label_bias</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>article</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YouTube is making clear there will be no “birt...</td>\n",
       "      <td>https://eu.usatoday.com/story/tech/2020/02/03/...</td>\n",
       "      <td>usa-today</td>\n",
       "      <td>elections-2020</td>\n",
       "      <td>center</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>YouTube says no ‘deepfakes’ or ‘birther’ video...</td>\n",
       "      <td>['belated', 'birtherism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So while there may be a humanitarian crisis dr...</td>\n",
       "      <td>https://www.alternet.org/2019/01/here-are-5-of...</td>\n",
       "      <td>alternet</td>\n",
       "      <td>immigration</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>Speaking to the country for the first time fro...</td>\n",
       "      <td>['crisis']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Looking around the United States, there is nev...</td>\n",
       "      <td>https://thefederalist.com/2020/03/11/woman-who...</td>\n",
       "      <td>federalist</td>\n",
       "      <td>abortion</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>The left has a thing for taking babies hostage...</td>\n",
       "      <td>['killing', 'never', 'developing', 'humans', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Republican president assumed he was helpin...</td>\n",
       "      <td>http://www.msnbc.com/rachel-maddow-show/auto-i...</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>environment</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>In Barack Obama’s first term, the administrati...</td>\n",
       "      <td>['rejects', 'happy', 'assumed']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The explosion of the Hispanic population has l...</td>\n",
       "      <td>https://www.breitbart.com/politics/2015/02/26/...</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>student-debt</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>No agreement</td>\n",
       "      <td>Republicans should stop fighting amnesty, Pres...</td>\n",
       "      <td>['explosion']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  YouTube is making clear there will be no “birt...   \n",
       "1  So while there may be a humanitarian crisis dr...   \n",
       "2  Looking around the United States, there is nev...   \n",
       "3  The Republican president assumed he was helpin...   \n",
       "4  The explosion of the Hispanic population has l...   \n",
       "\n",
       "                                           news_link      outlet  \\\n",
       "0  https://eu.usatoday.com/story/tech/2020/02/03/...   usa-today   \n",
       "1  https://www.alternet.org/2019/01/here-are-5-of...    alternet   \n",
       "2  https://thefederalist.com/2020/03/11/woman-who...  federalist   \n",
       "3  http://www.msnbc.com/rachel-maddow-show/auto-i...       msnbc   \n",
       "4  https://www.breitbart.com/politics/2015/02/26/...   breitbart   \n",
       "\n",
       "            topic    type  group_id  num_sent label_bias  \\\n",
       "0  elections-2020  center         1         1     Biased   \n",
       "1     immigration    left         1         1     Biased   \n",
       "2        abortion   right         1         1     Biased   \n",
       "3     environment    left         1         1     Biased   \n",
       "4    student-debt   right         1         1     Biased   \n",
       "\n",
       "                           label_opinion  \\\n",
       "0  Somewhat factual but also opinionated   \n",
       "1             Expresses writer’s opinion   \n",
       "2  Somewhat factual but also opinionated   \n",
       "3             Expresses writer’s opinion   \n",
       "4                           No agreement   \n",
       "\n",
       "                                             article  \\\n",
       "0  YouTube says no ‘deepfakes’ or ‘birther’ video...   \n",
       "1  Speaking to the country for the first time fro...   \n",
       "2  The left has a thing for taking babies hostage...   \n",
       "3  In Barack Obama’s first term, the administrati...   \n",
       "4  Republicans should stop fighting amnesty, Pres...   \n",
       "\n",
       "                                        biased_words  \n",
       "0                          ['belated', 'birtherism']  \n",
       "1                                         ['crisis']  \n",
       "2  ['killing', 'never', 'developing', 'humans', '...  \n",
       "3                    ['rejects', 'happy', 'assumed']  \n",
       "4                                      ['explosion']  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "data = pd.read_csv('final_labels.csv', sep=';')\n",
    "# Display the first few rows of the dataset\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5b3d0",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d5b3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'news_link',\n",
       " 'outlet',\n",
       " 'topic',\n",
       " 'type',\n",
       " 'group_id',\n",
       " 'num_sent',\n",
       " 'label_bias',\n",
       " 'label_opinion',\n",
       " 'article',\n",
       " 'biased_words']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the column names of the dataset\n",
    "column_names = data.columns.tolist()\n",
    "display(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d26f32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'news_link', 'outlet', 'topic', 'type', 'group_id', 'num_sent',\n",
      "       'label_bias', 'label_opinion', 'article', 'biased_words'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "data.columns = [re.sub(r'(?<!^)(?=[A-Z])', '_', col).lower() for col in data.columns]\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7650572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'news_link',\n",
       " 'outlet',\n",
       " 'topic',\n",
       " 'type',\n",
       " 'group_id',\n",
       " 'num_sent',\n",
       " 'label_bias',\n",
       " 'label_opinion',\n",
       " 'article',\n",
       " 'biased_words']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the column names of the dataset\n",
    "column_names = data.columns.tolist()\n",
    "display(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebfa8dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame has 1700 rows and 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the dataset\n",
    "n_rows, n_cols = data.shape\n",
    "print(f\"The DataFrame has {n_rows} rows and {n_cols} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3998e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1700 entries, 0 to 1699\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   text           1700 non-null   object\n",
      " 1   news_link      1681 non-null   object\n",
      " 2   outlet         1700 non-null   object\n",
      " 3   topic          1700 non-null   object\n",
      " 4   type           1700 non-null   object\n",
      " 5   group_id       1700 non-null   int64 \n",
      " 6   num_sent       1700 non-null   int64 \n",
      " 7   label_bias     1700 non-null   object\n",
      " 8   label_opinion  1700 non-null   object\n",
      " 9   article        1595 non-null   object\n",
      " 10  biased_words   1700 non-null   object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 146.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display the informative summary of the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "486f9a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>num_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.124706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.542908</td>\n",
       "      <td>0.414256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          group_id     num_sent\n",
       "count  1700.000000  1700.000000\n",
       "mean     43.000000     1.124706\n",
       "std      24.542908     0.414256\n",
       "min       1.000000     1.000000\n",
       "25%      22.000000     1.000000\n",
       "50%      43.000000     1.000000\n",
       "75%      64.000000     1.000000\n",
       "max      85.000000     5.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the descriptive statistics of the dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc2dbd",
   "metadata": {},
   "source": [
    "## 2. You will conduct EDA that you see fit to appropriately investigate text of wikipedia articles you look to predict on for biased terms, sentiment, or other linguistic significance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910da4e2",
   "metadata": {},
   "source": [
    "## Explorating Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9456da3",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "998ad12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of duplicated data: 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the number of duplicates in the dataset\n",
    "duplicates = data[data.duplicated()]\n",
    "display(f\"Number of duplicated data: {duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46d36b",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75c2a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text               0\n",
       "news_link         19\n",
       "outlet             0\n",
       "topic              0\n",
       "type               0\n",
       "group_id           0\n",
       "num_sent           0\n",
       "label_bias         0\n",
       "label_opinion      0\n",
       "article          105\n",
       "biased_words       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text             0.000000\n",
       "news_link        0.011176\n",
       "outlet           0.000000\n",
       "topic            0.000000\n",
       "type             0.000000\n",
       "group_id         0.000000\n",
       "num_sent         0.000000\n",
       "label_bias       0.000000\n",
       "label_opinion    0.000000\n",
       "article          0.061765\n",
       "biased_words     0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the number of missing values in the dataset\n",
    "display(data.isna().sum())\n",
    "\n",
    "# Check for missing values in the DataFrame as a percentage\n",
    "display(data.isna().sum()/len(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40cde572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the 'type' column\n",
    "data.dropna(subset=['type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b12601f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text             0.000000\n",
       "news_link        0.011176\n",
       "outlet           0.000000\n",
       "topic            0.000000\n",
       "type             0.000000\n",
       "group_id         0.000000\n",
       "num_sent         0.000000\n",
       "label_bias       0.000000\n",
       "label_opinion    0.000000\n",
       "article          0.061765\n",
       "biased_words     0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for missing values in the DataFrame as a percentage\n",
    "display(data.isna().sum()/len(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81246efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text data in the 'text' column\n",
    "# Define a function to clean the text data \n",
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\",\"\", text)\n",
    "    text = text.split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abffc4ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentence'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentence'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply the clear_text function to the 'comment_text' column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(clear_text) \n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Display the first 5 rows of the comments DataFrame after cleaning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jeelf\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentence'"
     ]
    }
   ],
   "source": [
    "# Apply the clear_text function to the 'comment_text' column\n",
    "data['clean_text'] = data['sentence'].astype(str).apply(clear_text) \n",
    "data= data.drop(columns=['sentence'])\n",
    "\n",
    "# Display the first 5 rows of the comments DataFrame after cleaning\n",
    "display(data.sample(5)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b0b8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data['clean_text'].isna().sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49616 entries, 0 to 65821\n",
      "Columns: 301 entries, Unnamed: 0 to clean_text\n",
      "dtypes: bool(2), float64(4), int64(281), object(14)\n",
      "memory usage: 113.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set of English stop words\n",
    "stop_words =  set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def lemmatize(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57095114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clear_text function to the 'comment_text' column\n",
    "data['lemmatize_text'] = data['clean_text'].apply(lemmatize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e568e71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemmatize_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40603</th>\n",
       "      <td>schlapps apology comes as the us is convulsed ...</td>\n",
       "      <td>schlapps apology come u convulsed protest poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>a us official speaking on condition of anonymi...</td>\n",
       "      <td>u official speaking condition anonymity confir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34458</th>\n",
       "      <td>once powerful hollywood producer harvey weinst...</td>\n",
       "      <td>powerful hollywood producer harvey weinstein c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48880</th>\n",
       "      <td>the leftwing mob had gathered in parliament sq...</td>\n",
       "      <td>leftwing mob gathered parliament square london...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36679</th>\n",
       "      <td>president donald trump has characterized those...</td>\n",
       "      <td>president donald trump characterized clashing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  \\\n",
       "40603  schlapps apology comes as the us is convulsed ...   \n",
       "2548   a us official speaking on condition of anonymi...   \n",
       "34458  once powerful hollywood producer harvey weinst...   \n",
       "48880  the leftwing mob had gathered in parliament sq...   \n",
       "36679  president donald trump has characterized those...   \n",
       "\n",
       "                                          lemmatize_text  \n",
       "40603  schlapps apology come u convulsed protest poli...  \n",
       "2548   u official speaking condition anonymity confir...  \n",
       "34458  powerful hollywood producer harvey weinstein c...  \n",
       "48880  leftwing mob gathered parliament square london...  \n",
       "36679  president donald trump characterized clashing ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 5 rows of the comments DataFrame after cleaning\n",
    "display(data[['clean_text', 'lemmatize_text']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c4e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49616, 302)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a9600",
   "metadata": {},
   "source": [
    "## 3. You will conduct supervised learning to be able to predict if a given text is biased. You might want to be able to do this on the sentence by sentence level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0321534",
   "metadata": {},
   "source": [
    "## 4. You need to have a prediction function that can take in a new wikipedia article and predict how biased it is. You can do this by predicting if each sentence in an article is biased, then perhaps scaling the results by the length of the article to get somewhat of a“bias score”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
